# NLP paper_with_code
The main goal is to collect NLP related classical and solid work with great reproductions or open-source codes released by the author

# Table of Contents
<details>

<summary><b>Expand Table of Contents</b></summary><blockquote><p align="justify">

- [NLP paper_with_code](#nlp-paper_with_code)
- [Table of Contents](#table-of-contents)
  - [Event Extraction](#event-extraction)

</p></blockquote></details>

---

## Event Extraction
* Open Domain Event Extraction from Twitter  [pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.481.6809&rep=rep1&type=pdf)
author: [OSU Twitter NLP Tools](https://github.com/aritter/twitter_nlp)
* Snorkel-- rapid training data creation with weak supervision  [arxiv](https://arxiv.org/abs/1711.10160)
  Data Programming:Creating Large Training Sets, Quickly [arxiv](https://arxiv.org/abs/1605.07723)
  Learning the Structure of Generative Models without Labeled Data [arxiv](https://arxiv.org/abs/1703.00854)
  Snorkel [snorkel-Programmatically Build Training Data](https://www.snorkel.org/)
* Learning Named Entity Tagger using Domain-Specific Dictionary——AutoNER [pdf](https://arxiv.org/pdf/1809.03599.pdf)
  author: [AutoNER](https://shangjingbo1226.github.io/AutoNER/)
* Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision [pdf]()
  author: [RINANTE](https://github.com/HKUST-KnowComp/RINANTE)
* A Short Introduction to Probabilistic Soft Logic [pdf](http://cs.brown.edu/people/sbach/files/kimmig-probprog12.pdf)
  author: [PSL](https://psl.linqs.org/)
* Harnessing Deep Neural Networks with Logic Rules [arxiv](https://arxiv.org/abs/1603.06318)
  author: [An implementation of the in application of sentiment classification](https://github.com/ZhitingHu/logicnn)
  related paper implementation: [Logic Rules for Sentiment Classification](https://github.com/martiansideofthemoon/logic-rules-sentiment)
* DL2- TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC [pdf](https://files.sri.inf.ethz.ch/website/papers/icml19-dl2.pdf)
  author: [Dl2](https://github.com/eth-sri/dl2)
  [SRILAB](https://eth-sri.github.io/publications/fischer2019dl2)
* Neural Module Networks [arxiv](arxiv.org/abs/1511.02799)
  author: [code](https://github.com/jacobandreas/nmn2)
  Code for end-to-end module network framework is available at https://github.com/ronghanghu/n2nmn
* The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision [arxiv](https://arxiv.org/abs/1904.12584)
  author: [PyTorch implementation for the Neuro-Symbolic Concept Learner (NS-CL)](https://github.com/vacancy/NSCL-PyTorch-Release)
* What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision? [arxiv](https://arxiv.org/abs/1703.04977)
  reproduction: [paperwithcode](https://paperswithcode.com/paper/what-uncertainties-do-we-need-in-bayesian)
* Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning [arxiv](https://arxiv.org/pdf/1506.02142)
  author: [Experiments used in "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning"](https://github.com/yaringal/DropoutUncertaintyExps)
* On Calibration of Modern Neural Networks [author's blog](https://geoffpleiss.com/nn_calibration)
  author: [A simple way to calibrate your neural network.](https://github.com/gpleiss/temperature_scaling)